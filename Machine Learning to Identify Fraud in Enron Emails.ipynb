{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e77bdf28",
   "metadata": {},
   "source": [
    "# Machine Learning to Identify Fraud in Enron Emails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd3d80e",
   "metadata": {},
   "source": [
    "## Jean Phillips\n",
    "## 8/8/2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bdb374",
   "metadata": {},
   "source": [
    "## Introduction  / Project Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebada9b",
   "metadata": {},
   "source": [
    "Enron was a major financial corporation in the early 2000's, but went bankrupt due to widespread, major financial fraud. Following the investigation into Enron, thousands of emails and otherwise confidential information was made public. That information forms the foundation of this dataset, which includes financial information and emails for many Enron employees. \n",
    "\n",
    "The provided dataset is in the form of a dictionary, where each key-value pair in the dictionary corresponds to one person. The dictionary key is the person's name, and the value is another dictionary, which contains the names of all the features and their values for that person. The features in the data fall into three major types, namely financial features, email features and POI labels.\n",
    "\n",
    "The goal of this project is to use machine learning to create an algorithm to identify potential persons of interest (POI) in the dataset who may have contributed to the fraud at Enron. This algorithm should have a precision and recall of at least 0.3 per the project rubric specifications.\n",
    "\n",
    "Machine learning is well-suited to this type of task as it will be able to detect patterns in a large dataset such as this much more efficiently than a human being would be able to do. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f9104a",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66859e97",
   "metadata": {},
   "source": [
    "The dataset for this project is provided to students as \"final_project_dataset.pkl.\" Printing some basic information about the dataset shows the following: \n",
    "- There are 146 rows in the data\n",
    "- There are 21 features in the data, ranging from financial information such as salary and bonus, to personal information such as email address\n",
    "- Of the 146 rows in the data, 18 represent persons of interest and 128 represent non-persons of interest\n",
    "\n",
    "There are three different groupings of data in the dataset, namely payment, stock and email information. These groupings can be broken downs as follows:\n",
    "- Payment: salary, bonus, long_term_incentive, deferred_income, deferral_payments, loan_advances, other, expenses, director_fees, and total_payments\n",
    "- Stock: exercised_stock_options, restricted_stock, restricted_stock_deferred, total_stock_value\n",
    "- Email information: from_poi_to_this_person, shared_receipt_with_poi, from_this_person_to_poi, to_messages, and from_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "43ac1cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 146\n",
      "Data features:\n",
      "['salary',\n",
      " 'to_messages',\n",
      " 'deferral_payments',\n",
      " 'total_payments',\n",
      " 'loan_advances',\n",
      " 'bonus',\n",
      " 'email_address',\n",
      " 'restricted_stock_deferred',\n",
      " 'deferred_income',\n",
      " 'total_stock_value',\n",
      " 'expenses',\n",
      " 'from_poi_to_this_person',\n",
      " 'exercised_stock_options',\n",
      " 'from_messages',\n",
      " 'other',\n",
      " 'from_this_person_to_poi',\n",
      " 'poi',\n",
      " 'long_term_incentive',\n",
      " 'shared_receipt_with_poi',\n",
      " 'restricted_stock',\n",
      " 'director_fees']\n",
      "Number of features: 21\n",
      "Number of POI:  18\n",
      "Non-PoIs:  128\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from pprint import pprint as pp\n",
    "# load pickle file to Python dict to show length and features of dataset\n",
    "with open(\"final_project_dataset.pkl\", \"rb\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n",
    "print(\"Number of rows:\", len(data_dict))\n",
    "features = []\n",
    "poi_count = 0\n",
    "for k in data_dict.keys():\n",
    "    for d in data_dict[k]:\n",
    "        if d not in features:\n",
    "            features.append(d)\n",
    "    if data_dict[k]['poi']:\n",
    "        poi_count += 1\n",
    "print(\"Data features:\")\n",
    "pp(features)\n",
    "print(\"Number of features:\", len(features))\n",
    "print(\"Number of POI: \", poi_count)\n",
    "print(\"Non-PoIs: \", len(data_dict) - poi_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e69f33",
   "metadata": {},
   "source": [
    "I realized very quickly that there would not be a lot of information to glean from the \"email_address\" column, as this was typically just the individuals name reformatted as an email address. For that reason, this column was removed from the data. \n",
    "\n",
    "Following that cleaning, I decided to investigate missing values in the dataset as denoted by \"NaN\" or not a number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9ee34ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current features in the dataset: 20\n",
      "\n",
      "'NaN' (missing) values in the dataset, by feature:\n",
      "{'bonus': 64,\n",
      " 'deferral_payments': 107,\n",
      " 'deferred_income': 97,\n",
      " 'director_fees': 129,\n",
      " 'exercised_stock_options': 44,\n",
      " 'expenses': 51,\n",
      " 'from_messages': 60,\n",
      " 'from_poi_to_this_person': 60,\n",
      " 'from_this_person_to_poi': 60,\n",
      " 'loan_advances': 142,\n",
      " 'long_term_incentive': 80,\n",
      " 'other': 53,\n",
      " 'poi': 0,\n",
      " 'restricted_stock': 36,\n",
      " 'restricted_stock_deferred': 128,\n",
      " 'salary': 51,\n",
      " 'shared_receipt_with_poi': 60,\n",
      " 'to_messages': 60,\n",
      " 'total_payments': 21,\n",
      " 'total_stock_value': 20}\n"
     ]
    }
   ],
   "source": [
    "#remove email addresses\n",
    "for k in data_dict.keys():\n",
    "  if 'email_address' in data_dict[k].keys():\n",
    "    data_dict[k].pop('email_address', 0)\n",
    "\n",
    "print(\"\\nCurrent features in the dataset:\", len(features)-1)\n",
    "missing_values = {'salary' : 0,\n",
    "                  'to_messages' : 0,\n",
    "                  'deferral_payments' : 0,\n",
    "                  'total_payments' : 0,\n",
    "                  'loan_advances' : 0,\n",
    "                  'bonus' : 0,\n",
    "                  'restricted_stock_deferred' : 0,\n",
    "                  'deferred_income' : 0,\n",
    "                  'total_stock_value' : 0,\n",
    "                  'expenses' : 0,\n",
    "                  'from_poi_to_this_person' : 0,\n",
    "                  'exercised_stock_options' : 0,\n",
    "                  'from_messages' : 0,\n",
    "                  'other' : 0,\n",
    "                  'from_this_person_to_poi' : 0,\n",
    "                  'poi' : 0,\n",
    "                  'long_term_incentive' : 0,\n",
    "                  'shared_receipt_with_poi' : 0,\n",
    "                  'restricted_stock' : 0,\n",
    "                  'director_fees' : 0}\n",
    "for k in data_dict.keys():\n",
    "    for d in data_dict[k]:\n",
    "        if data_dict[k][d] == 'NaN':\n",
    "            missing_values[d] += 1\n",
    "print(\"\\n'NaN' (missing) values in the dataset, by feature:\")\n",
    "pp(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9217a18d",
   "metadata": {},
   "source": [
    "The only row which is not missing values is \"poi\", which makes sense as this is the row created and added to the dataset by Udacity to classify the data. \n",
    "\n",
    "There are many varying values of NaN. It is interesting to note that for email-related columns (from_messages, from_poi_to_this_person, from_this_person_to_poi, shared_receipt_with_poi, to_messages) there is a consistent number of missing values at 60. Upon looking at the data set, it becomes apparaent that a row either has all email-associated data, or no email-associated data, thus this pattern makes sense. \n",
    "\n",
    "I decided to take a look at rows that were missing more than 15 features. These rows are not likely to offer much in the way of predictive value given how much data they are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e77dbd34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records with less than 5 nonmissing values:\n",
      "CHRISTODOULOU DIOMEDES\n",
      "  total_stock_value : 6077885\n",
      "  exercised_stock_options : 5127155\n",
      "  poi : False\n",
      "  restricted_stock : 950730\n",
      "CLINE KENNETH W\n",
      "  restricted_stock_deferred : -472568\n",
      "  total_stock_value : 189518\n",
      "  poi : False\n",
      "  restricted_stock : 662086\n",
      "GILLIS JOHN\n",
      "  total_stock_value : 85641\n",
      "  exercised_stock_options : 9803\n",
      "  poi : False\n",
      "  restricted_stock : 75838\n",
      "GRAMM WENDY L\n",
      "  total_payments : 119292\n",
      "  poi : False\n",
      "  director_fees : 119292\n",
      "LOCKHART EUGENE E\n",
      "  poi : False\n",
      "SAVAGE FRANK\n",
      "  total_payments : 3750\n",
      "  deferred_income : -121284\n",
      "  poi : False\n",
      "  director_fees : 125034\n",
      "SCRIMSHAW MATTHEW\n",
      "  total_stock_value : 759557\n",
      "  exercised_stock_options : 759557\n",
      "  poi : False\n",
      "THE TRAVEL AGENCY IN THE PARK\n",
      "  total_payments : 362096\n",
      "  other : 362096\n",
      "  poi : False\n",
      "WAKEHAM JOHN\n",
      "  total_payments : 213071\n",
      "  expenses : 103773\n",
      "  poi : False\n",
      "  director_fees : 109298\n",
      "WHALEY DAVID A\n",
      "  total_stock_value : 98718\n",
      "  exercised_stock_options : 98718\n",
      "  poi : False\n",
      "WODRASKA JOHN\n",
      "  total_payments : 189583\n",
      "  other : 189583\n",
      "  poi : False\n",
      "WROBEL BRUCE\n",
      "  total_stock_value : 139130\n",
      "  exercised_stock_options : 139130\n",
      "  poi : False\n",
      "Number of records with less than 5 nonmissing values:\n",
      "  12\n"
     ]
    }
   ],
   "source": [
    "# populating a dictionary with rows with less than 5 nonmissing values\n",
    "empty_features = {}\n",
    "for k in data_dict.keys():\n",
    "  empty_features[k] = []\n",
    "  for d in data_dict[k]:\n",
    "    if data_dict[k][d] == 'NaN':\n",
    "      empty_features[k].append(1)\n",
    "  empty_features[k] = sum(empty_features[k])\n",
    "count = 0\n",
    "print(\"Records with less than 5 nonmissing values:\")\n",
    "for k in sorted(empty_features):\n",
    "  if empty_features[k] > 15:\n",
    "    print(k)\n",
    "    for d in data_dict[k]:\n",
    "      if data_dict[k][d] != 'NaN':\n",
    "        print(\"  %s : %s\" % (d, data_dict[k][d]))\n",
    "    count += 1\n",
    "print(\"Number of records with less than 5 nonmissing values:\")\n",
    "print(\" \",count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14128d9",
   "metadata": {},
   "source": [
    "What is striking about the above results is the row for \"LOCKHART EUGENE E\" is missing values for everything except \"Poi\", so it makes sense to remove this row. Additionally, \"THE TRAVEL AGENCY IN THE PARK\" appears to be a business rather than a person, so this will be excluded as well. The other values will be left even though they may represent outliers, as they may still have some valuable predictive information for the algorithm we will build. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f9776f",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b238b8",
   "metadata": {},
   "source": [
    "As discussed in the previous section, there are issues with the data. The rows for \"LOCKHART EUGENE E\" as well as for \"THE TRAVEL AGENCY IN THE PARK\" will be removed, as \"LOCKHART EUGENE E\" has no data and \"THE TRAVEL AGENCY IN THE PARK\" represents a non-human entity. Another row that sticks out is the \"TOTAL\" row. This is an aggregate row comprised of financial data. There is little predictive value here and it is a major outlier, so it will also be removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "91197f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'TOTAL':\n",
      "{'bonus': 97343619,\n",
      " 'deferral_payments': 32083396,\n",
      " 'deferred_income': -27992891,\n",
      " 'director_fees': 1398517,\n",
      " 'exercised_stock_options': 311764000,\n",
      " 'expenses': 5235198,\n",
      " 'from_messages': 'NaN',\n",
      " 'from_poi_to_this_person': 'NaN',\n",
      " 'from_this_person_to_poi': 'NaN',\n",
      " 'loan_advances': 83925000,\n",
      " 'long_term_incentive': 48521928,\n",
      " 'other': 42667589,\n",
      " 'poi': False,\n",
      " 'restricted_stock': 130322299,\n",
      " 'restricted_stock_deferred': -7576788,\n",
      " 'salary': 26704229,\n",
      " 'shared_receipt_with_poi': 'NaN',\n",
      " 'to_messages': 'NaN',\n",
      " 'total_payments': 309886585,\n",
      " 'total_stock_value': 434509511}\n"
     ]
    }
   ],
   "source": [
    "print(\"'TOTAL':\")\n",
    "pp(data_dict['TOTAL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "41f557b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows remaining in the dataset: 143\n"
     ]
    }
   ],
   "source": [
    "#removing eugene lockhart row\n",
    "data_dict.pop('LOCKHART EUGENE E', 0)\n",
    "# remove the  aggregate row TOTAL\n",
    "data_dict.pop('TOTAL', 0)\n",
    "# remove the non-person row THE TRAVEL AGENCY IN THE PARK\n",
    "data_dict.pop('THE TRAVEL AGENCY IN THE PARK', 0)\n",
    "print(\"Rows remaining in the dataset:\",len(data_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de96127",
   "metadata": {},
   "source": [
    "Another way to investigate the dataset and assess it for issues is to look at the financial data. One check is to add together the various financial entries and compare that information to total_payments. It would make sense for the aggregated total to equal total_payments and would bear further investigating if it did not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c38f2c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problems with 'total_payments' :found.\n",
      "Records with problems related to 'total_payments' found: \n",
      "{'BELFER ROBERT': {'bonus': 'NaN',\n",
      "                   'deferral_payments': -102500,\n",
      "                   'deferred_income': 'NaN',\n",
      "                   'director_fees': 3285,\n",
      "                   'exercised_stock_options': 3285,\n",
      "                   'expenses': 'NaN',\n",
      "                   'from_messages': 'NaN',\n",
      "                   'from_poi_to_this_person': 'NaN',\n",
      "                   'from_this_person_to_poi': 'NaN',\n",
      "                   'loan_advances': 'NaN',\n",
      "                   'long_term_incentive': 'NaN',\n",
      "                   'other': 'NaN',\n",
      "                   'poi': False,\n",
      "                   'restricted_stock': 'NaN',\n",
      "                   'restricted_stock_deferred': 44093,\n",
      "                   'salary': 'NaN',\n",
      "                   'shared_receipt_with_poi': 'NaN',\n",
      "                   'to_messages': 'NaN',\n",
      "                   'total_payments': 102500,\n",
      "                   'total_stock_value': -44093},\n",
      " 'BHATNAGAR SANJAY': {'bonus': 'NaN',\n",
      "                      'deferral_payments': 'NaN',\n",
      "                      'deferred_income': 'NaN',\n",
      "                      'director_fees': 137864,\n",
      "                      'exercised_stock_options': 2604490,\n",
      "                      'expenses': 'NaN',\n",
      "                      'from_messages': 29,\n",
      "                      'from_poi_to_this_person': 0,\n",
      "                      'from_this_person_to_poi': 1,\n",
      "                      'loan_advances': 'NaN',\n",
      "                      'long_term_incentive': 'NaN',\n",
      "                      'other': 137864,\n",
      "                      'poi': False,\n",
      "                      'restricted_stock': -2604490,\n",
      "                      'restricted_stock_deferred': 15456290,\n",
      "                      'salary': 'NaN',\n",
      "                      'shared_receipt_with_poi': 463,\n",
      "                      'to_messages': 523,\n",
      "                      'total_payments': 15456290,\n",
      "                      'total_stock_value': 'NaN'}}\n"
     ]
    }
   ],
   "source": [
    "print(\"Problems with 'total_payments' :\", end='')\n",
    "payment_financial_features = ['salary',\n",
    "                              'bonus',\n",
    "                              'long_term_incentive',\n",
    "                              'expenses',\n",
    "                              'director_fees',\n",
    "                              'other',\n",
    "                              'loan_advances',\n",
    "                              'deferred_income',\n",
    "                              'deferral_payments']\n",
    "problem_entries = {}\n",
    "# Iterate over each row, check sum of financial features against total_payments,add rows with issues to problem_entries\n",
    "for k in data_dict.keys():\n",
    "  total_payments_check = 0\n",
    "  for d in data_dict[k]:\n",
    "    if d in payment_financial_features and data_dict[k][d] != 'NaN':\n",
    "      total_payments_check += data_dict[k][d]\n",
    "  if data_dict[k]['total_payments'] != 'NaN' and \\\n",
    "                        total_payments_check != data_dict[k]['total_payments']:\n",
    "    problem_entries[k] = data_dict[k]\n",
    "from pprint import pprint as pp\n",
    "if len(problem_entries):\n",
    "  print(\"found.\")\n",
    "  print(\"Records with problems related to 'total_payments' found: \")\n",
    "  pp(problem_entries)\n",
    "else:\n",
    "  print(\"None.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2afdf35",
   "metadata": {},
   "source": [
    "The values for total_payments for individuals Belfer and Bhatnagar do not appear to be correct. In comparing the values seen here with the information provided in the enron61702insiderpay.pdf document, it appears that these values have been shifted, Belfer to the right and Bhatnagar to the left. This was corrected by recreating entries for these two individuals with the correct data as found within the enron61702insiderpay.pdf document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d761b517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# records for Belfer corrected based off data found in pdf fie\n",
    "belfer_corrected = {'bonus': 'NaN',\n",
    "                    'deferral_payments': 0,                  \n",
    "                    'deferred_income': -102500,              \n",
    "                    'director_fees': 102500,                 \n",
    "                    'exercised_stock_options': 0,            \n",
    "                    'expenses': 3285,                        \n",
    "                    'from_messages': 'NaN',\n",
    "                    'from_poi_to_this_person': 'NaN',\n",
    "                    'from_this_person_to_poi': 'NaN',\n",
    "                    'loan_advances': 'NaN',\n",
    "                    'long_term_incentive': 'NaN',\n",
    "                    'other': 'NaN',\n",
    "                    'poi': False,\n",
    "                    'restricted_stock': 44093,                \n",
    "                    'restricted_stock_deferred': -44093,      \n",
    "                    'salary': 'NaN',\n",
    "                    'shared_receipt_with_poi': 'NaN',\n",
    "                    'to_messages': 'NaN',\n",
    "                    'total_payments': 3285,                   \n",
    "                    'total_stock_value': 0}                   \n",
    "\n",
    "# similar correction for Bhatnagar from data found in pdf file\n",
    "bhatnagar_corrected = {'bonus': 'NaN',\n",
    "                       'deferral_payments': 'NaN',\n",
    "                       'deferred_income': 'NaN',\n",
    "                       'director_fees': 0,                    \n",
    "                       'exercised_stock_options': 15456290,   \n",
    "                       'expenses': 137864,                    \n",
    "                       'from_messages': 29,\n",
    "                       'from_poi_to_this_person': 0,\n",
    "                       'from_this_person_to_poi': 1,\n",
    "                       'loan_advances': 'NaN',\n",
    "                       'long_term_incentive': 'NaN',\n",
    "                       'other': 0,                            \n",
    "                       'poi': False,\n",
    "                       'restricted_stock': 2604490,           \n",
    "                       'restricted_stock_deferred': -2604490, \n",
    "                       'salary': 'NaN',\n",
    "                       'shared_receipt_with_poi': 463,\n",
    "                       'to_messages': 523,\n",
    "                       'total_payments': 137864,              \n",
    "                       'total_stock_value': 15456290}         \n",
    "\n",
    "data_dict['BELFER ROBERT'] = belfer_corrected\n",
    "data_dict['BHATNAGAR SANJAY'] = bhatnagar_corrected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cb88b7",
   "metadata": {},
   "source": [
    "With those entries corrected, we can re-run the total_payment check to ensure no further issues have arisen, which appears to be the case here. \n",
    "\n",
    "No further cleaning or removal of outliers was undertaken. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5e0fd133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second check for problems with 'total_payments' :None.\n"
     ]
    }
   ],
   "source": [
    "# Repeating check to verify changes\n",
    "print(\"Second check for problems with 'total_payments' :\", end='')\n",
    "problem_entries = {}\n",
    "for k in data_dict.keys():\n",
    "  total_payments_check = 0\n",
    "  for d in data_dict[k]:\n",
    "    if d in payment_financial_features and data_dict[k][d] != 'NaN':\n",
    "      total_payments_check += data_dict[k][d]\n",
    "  if data_dict[k]['total_payments'] != 'NaN' and \\\n",
    "    total_payments_check != data_dict[k]['total_payments']:\n",
    "    problem_entries[k] = data_dict[k]\n",
    "\n",
    "if len(problem_entries):\n",
    "  print(\"found.\")\n",
    "  print(\"Records with problems related to 'total_payments' found:\")\n",
    "  pp(problem_entries)\n",
    "else:\n",
    "  print(\"None.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c8620e",
   "metadata": {},
   "source": [
    "## Feature Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338349f3",
   "metadata": {},
   "source": [
    "Having investigated the quantity of NaN values in the dataset and having seen the wide variability of these values across rows, it seemed prudent to focus on the email data since that was most consistent across the dataset. For that data, rows are either completely NaN or completely full of integer data. For that reason, ratios based on the email data were chosen for new feature creation:\n",
    "- ratio of emails sent to PoIs versus emails sent in general:\n",
    "    - to_poi_from_messages_ratio = from_this_person_to_poi / from_message\n",
    "- ratio of emails received from PoIs versus emails received in general:\n",
    "    - from_poi_to_messages_ratio = from_poi_to_this_person / to_messages\n",
    "- ratio of emails having shared receipt with PoI versus emails received in general:\n",
    "    - shared_receipt_to_messages_ratio = shared_receipt_with_poi / to_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0eb9f31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to create new features\n",
    "for k in data_dict.keys():\n",
    "  from_messages = True if \\\n",
    "    (data_dict[k]['from_messages'] != 'NaN') else False\n",
    "  to_messages = True if \\\n",
    "    (data_dict[k]['to_messages'] != 'NaN') else False\n",
    "  to_poi = True if \\\n",
    "    (data_dict[k]['from_this_person_to_poi'] != 'NaN') else  False\n",
    "  from_poi = True if \\\n",
    "    (data_dict[k]['from_poi_to_this_person'] != 'NaN') else False\n",
    "  shared_receipt = True if \\\n",
    "    (data_dict[k]['shared_receipt_with_poi'] != 'NaN') else False\n",
    "\n",
    "  # ratio of emails sent to PoIs to emails sent in general:\n",
    "  # to_poi_from_messages_ratio = from_this_person_to_poi / from_messages\n",
    "  if to_poi and from_messages:\n",
    "    data_dict[k]['to_poi_from_messages_ratio'] = \\\n",
    "       data_dict[k]['from_this_person_to_poi'] / data_dict[k]['from_messages']\n",
    "  else:\n",
    "    data_dict[k]['to_poi_from_messages_ratio'] = 'NaN'\n",
    "\n",
    "  # ratio of emails received from PoIs to emails received in general:\n",
    "  # from_poi_to_messages_ratio = from_poi_to_this_person / to_messages\n",
    "  if from_poi and to_messages:\n",
    "    data_dict[k]['from_poi_to_messages_ratio'] = \\\n",
    "          data_dict[k]['from_poi_to_this_person'] / data_dict[k]['to_messages']\n",
    "  else:\n",
    "    data_dict[k]['from_poi_to_messages_ratio'] = 'NaN'\n",
    "  \n",
    "  # ratio of emails having shared receipt with PoIs to emails received in general:\n",
    "  # shared_receipt_to_messages_ratio = shared_receipt_with_poi / to_messages\n",
    "  if shared_receipt and to_messages:\n",
    "    data_dict[k]['shared_receipt_to_messages_ratio'] = \\\n",
    "       data_dict[k]['shared_receipt_with_poi'] / data_dict[k]['to_messages']\n",
    "  else:\n",
    "    data_dict[k]['shared_receipt_to_messages_ratio'] = 'NaN'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "981bfa7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METTS MARK\n",
      " to 807\n",
      " from 29\n",
      " to_poi 1\n",
      " to poi/from 0.034482758620689655\n",
      " from_poi 38\n",
      " from poi/to 0.04708798017348203\n",
      " shared 702\n",
      " shared/to  0.8698884758364313\n",
      "BAXTER JOHN C\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "ELLIOTT STEVEN\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "CORDES WILLIAM R\n",
      " to 764\n",
      " from 12\n",
      " to_poi 0\n",
      " to poi/from 0.0\n",
      " from_poi 10\n",
      " from poi/to 0.013089005235602094\n",
      " shared 58\n",
      " shared/to  0.07591623036649214\n",
      "HANNON KEVIN P\n",
      " to 1045\n",
      " from 32\n",
      " to_poi 21\n",
      " to poi/from 0.65625\n",
      " from_poi 32\n",
      " from poi/to 0.03062200956937799\n",
      " shared 1035\n",
      " shared/to  0.9904306220095693\n",
      "MORDAUNT KRISTINA M\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "MEYER ROCKFORD G\n",
      " to 232\n",
      " from 28\n",
      " to_poi 0\n",
      " to poi/from 0.0\n",
      " from_poi 0\n",
      " from poi/to 0.0\n",
      " shared 22\n",
      " shared/to  0.09482758620689655\n",
      "MCMAHON JEFFREY\n",
      " to 2355\n",
      " from 48\n",
      " to_poi 26\n",
      " to poi/from 0.5416666666666666\n",
      " from_poi 58\n",
      " from poi/to 0.024628450106157114\n",
      " shared 2228\n",
      " shared/to  0.9460721868365181\n",
      "HAEDICKE MARK E\n",
      " to 4009\n",
      " from 1941\n",
      " to_poi 61\n",
      " to poi/from 0.03142709943328181\n",
      " from_poi 180\n",
      " from poi/to 0.04489897730107259\n",
      " shared 1847\n",
      " shared/to  0.4607133948615615\n",
      "PIPER GREGORY F\n",
      " to 1238\n",
      " from 222\n",
      " to_poi 48\n",
      " to poi/from 0.21621621621621623\n",
      " from_poi 61\n",
      " from poi/to 0.049273021001615507\n",
      " shared 742\n",
      " shared/to  0.5993537964458805\n",
      "HUMPHREY GENE E\n",
      " to 128\n",
      " from 17\n",
      " to_poi 17\n",
      " to poi/from 1.0\n",
      " from_poi 10\n",
      " from poi/to 0.078125\n",
      " shared 119\n",
      " shared/to  0.9296875\n",
      "NOLES JAMES L\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "BLACHMAN JEREMY M\n",
      " to 2475\n",
      " from 14\n",
      " to_poi 2\n",
      " to poi/from 0.14285714285714285\n",
      " from_poi 25\n",
      " from poi/to 0.010101010101010102\n",
      " shared 2326\n",
      " shared/to  0.9397979797979797\n",
      "SUNDE MARTIN\n",
      " to 2647\n",
      " from 38\n",
      " to_poi 13\n",
      " to poi/from 0.34210526315789475\n",
      " from_poi 37\n",
      " from poi/to 0.013978088401964487\n",
      " shared 2565\n",
      " shared/to  0.9690215338118625\n",
      "GIBBS DANA R\n",
      " to 169\n",
      " from 12\n",
      " to_poi 0\n",
      " to poi/from 0.0\n",
      " from_poi 0\n",
      " from poi/to 0.0\n",
      " shared 23\n",
      " shared/to  0.13609467455621302\n",
      "LOWRY CHARLES P\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "COLWELL WESLEY\n",
      " to 1758\n",
      " from 40\n",
      " to_poi 11\n",
      " to poi/from 0.275\n",
      " from_poi 240\n",
      " from poi/to 0.13651877133105803\n",
      " shared 1132\n",
      " shared/to  0.6439135381114903\n",
      "MULLER MARK S\n",
      " to 136\n",
      " from 16\n",
      " to_poi 0\n",
      " to poi/from 0.0\n",
      " from_poi 12\n",
      " from poi/to 0.08823529411764706\n",
      " shared 114\n",
      " shared/to  0.8382352941176471\n",
      "JACKSON CHARLENE R\n",
      " to 258\n",
      " from 56\n",
      " to_poi 19\n",
      " to poi/from 0.3392857142857143\n",
      " from_poi 25\n",
      " from poi/to 0.09689922480620156\n",
      " shared 117\n",
      " shared/to  0.45348837209302323\n",
      "WESTFAHL RICHARD K\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "WALTERS GARETH W\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "WALLS JR ROBERT H\n",
      " to 671\n",
      " from 146\n",
      " to_poi 0\n",
      " to poi/from 0.0\n",
      " from_poi 17\n",
      " from poi/to 0.02533532041728763\n",
      " shared 215\n",
      " shared/to  0.3204172876304024\n",
      "KITCHEN LOUISE\n",
      " to 8305\n",
      " from 1728\n",
      " to_poi 194\n",
      " to poi/from 0.11226851851851852\n",
      " from_poi 251\n",
      " from poi/to 0.030222757375075255\n",
      " shared 3669\n",
      " shared/to  0.441782059000602\n",
      "CHAN RONNIE\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "BELFER ROBERT\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "SHANKMAN JEFFREY A\n",
      " to 3221\n",
      " from 2681\n",
      " to_poi 83\n",
      " to poi/from 0.030958597538232\n",
      " from_poi 94\n",
      " from poi/to 0.029183483390251473\n",
      " shared 1730\n",
      " shared/to  0.5371002794163303\n",
      "WODRASKA JOHN\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "BERGSIEKER RICHARD P\n",
      " to 383\n",
      " from 59\n",
      " to_poi 0\n",
      " to poi/from 0.0\n",
      " from_poi 4\n",
      " from poi/to 0.010443864229765013\n",
      " shared 233\n",
      " shared/to  0.608355091383812\n",
      "URQUHART JOHN A\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "BIBI PHILIPPE A\n",
      " to 1607\n",
      " from 40\n",
      " to_poi 8\n",
      " to poi/from 0.2\n",
      " from_poi 23\n",
      " from poi/to 0.01431238332296204\n",
      " shared 1336\n",
      " shared/to  0.8313627878033603\n",
      "RIEKER PAULA H\n",
      " to 1328\n",
      " from 82\n",
      " to_poi 48\n",
      " to poi/from 0.5853658536585366\n",
      " from_poi 35\n",
      " from poi/to 0.02635542168674699\n",
      " shared 1258\n",
      " shared/to  0.947289156626506\n",
      "WHALEY DAVID A\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "BECK SALLY W\n",
      " to 7315\n",
      " from 4343\n",
      " to_poi 386\n",
      " to poi/from 0.08887865530739121\n",
      " from_poi 144\n",
      " from poi/to 0.01968557758031442\n",
      " shared 2639\n",
      " shared/to  0.36076555023923446\n",
      "HAUG DAVID L\n",
      " to 573\n",
      " from 19\n",
      " to_poi 7\n",
      " to poi/from 0.3684210526315789\n",
      " from_poi 4\n",
      " from poi/to 0.006980802792321117\n",
      " shared 471\n",
      " shared/to  0.8219895287958116\n",
      "ECHOLS JOHN B\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "MENDELSOHN JOHN\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "HICKERSON GARY J\n",
      " to 1320\n",
      " from 27\n",
      " to_poi 1\n",
      " to poi/from 0.037037037037037035\n",
      " from_poi 40\n",
      " from poi/to 0.030303030303030304\n",
      " shared 900\n",
      " shared/to  0.6818181818181818\n",
      "CLINE KENNETH W\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "LEWIS RICHARD\n",
      " to 952\n",
      " from 26\n",
      " to_poi 0\n",
      " to poi/from 0.0\n",
      " from_poi 10\n",
      " from poi/to 0.01050420168067227\n",
      " shared 739\n",
      " shared/to  0.7762605042016807\n",
      "HAYES ROBERT E\n",
      " to 504\n",
      " from 12\n",
      " to_poi 0\n",
      " to poi/from 0.0\n",
      " from_poi 16\n",
      " from poi/to 0.031746031746031744\n",
      " shared 50\n",
      " shared/to  0.0992063492063492\n",
      "KOPPER MICHAEL J\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "LEFF DANIEL P\n",
      " to 2822\n",
      " from 63\n",
      " to_poi 14\n",
      " to poi/from 0.2222222222222222\n",
      " from_poi 67\n",
      " from poi/to 0.02374202693125443\n",
      " shared 2672\n",
      " shared/to  0.9468462083628633\n",
      "LAVORATO JOHN J\n",
      " to 7259\n",
      " from 2585\n",
      " to_poi 411\n",
      " to poi/from 0.15899419729206962\n",
      " from_poi 528\n",
      " from poi/to 0.07273729163796666\n",
      " shared 3962\n",
      " shared/to  0.5458052073288332\n",
      "BERBERIAN DAVID\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "DETMERING TIMOTHY J\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "WAKEHAM JOHN\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "POWERS WILLIAM\n",
      " to 653\n",
      " from 26\n",
      " to_poi 0\n",
      " to poi/from 0.0\n",
      " from_poi 0\n",
      " from poi/to 0.0\n",
      " shared 12\n",
      " shared/to  0.018376722817764167\n",
      "GOLD JOSEPH\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "BANNANTINE JAMES M\n",
      " to 566\n",
      " from 29\n",
      " to_poi 0\n",
      " to poi/from 0.0\n",
      " from_poi 39\n",
      " from poi/to 0.06890459363957598\n",
      " shared 465\n",
      " shared/to  0.8215547703180212\n",
      "DUNCAN JOHN H\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "SHAPIRO RICHARD S\n",
      " to 15149\n",
      " from 1215\n",
      " to_poi 65\n",
      " to poi/from 0.053497942386831275\n",
      " from_poi 74\n",
      " from poi/to 0.0048848108786058485\n",
      " shared 4527\n",
      " shared/to  0.29883160604660375\n",
      "SHERRIFF JOHN R\n",
      " to 3187\n",
      " from 92\n",
      " to_poi 23\n",
      " to poi/from 0.25\n",
      " from_poi 28\n",
      " from poi/to 0.008785691873235017\n",
      " shared 2103\n",
      " shared/to  0.6598682146219015\n",
      "SHELBY REX\n",
      " to 225\n",
      " from 39\n",
      " to_poi 14\n",
      " to poi/from 0.358974358974359\n",
      " from_poi 13\n",
      " from poi/to 0.057777777777777775\n",
      " shared 91\n",
      " shared/to  0.40444444444444444\n",
      "LEMAISTRE CHARLES\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "DEFFNER JOSEPH M\n",
      " to 714\n",
      " from 74\n",
      " to_poi 4\n",
      " to poi/from 0.05405405405405406\n",
      " from_poi 115\n",
      " from poi/to 0.16106442577030813\n",
      " shared 552\n",
      " shared/to  0.773109243697479\n",
      "KISHKILL JOSEPH G\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "WHALLEY LAWRENCE G\n",
      " to 6019\n",
      " from 556\n",
      " to_poi 24\n",
      " to poi/from 0.04316546762589928\n",
      " from_poi 186\n",
      " from poi/to 0.03090214321315833\n",
      " shared 3920\n",
      " shared/to  0.6512709752450573\n",
      "MCCONNELL MICHAEL S\n",
      " to 3329\n",
      " from 2742\n",
      " to_poi 194\n",
      " to poi/from 0.07075127644055434\n",
      " from_poi 92\n",
      " from poi/to 0.02763592670471613\n",
      " shared 2189\n",
      " shared/to  0.657554821267648\n",
      "PIRO JIM\n",
      " to 58\n",
      " from 16\n",
      " to_poi 1\n",
      " to poi/from 0.0625\n",
      " from_poi 0\n",
      " from poi/to 0.0\n",
      " shared 3\n",
      " shared/to  0.05172413793103448\n",
      "DELAINEY DAVID W\n",
      " to 3093\n",
      " from 3069\n",
      " to_poi 609\n",
      " to poi/from 0.198435972629521\n",
      " from_poi 66\n",
      " from poi/to 0.02133850630455868\n",
      " shared 2097\n",
      " shared/to  0.6779825412221144\n",
      "SULLIVAN-SHAKLOVITZ COLLEEN\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "WROBEL BRUCE\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "LINDHOLM TOD A\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "MEYER JEROME J\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "LAY KENNETH L\n",
      " to 4273\n",
      " from 36\n",
      " to_poi 16\n",
      " to poi/from 0.4444444444444444\n",
      " from_poi 123\n",
      " from poi/to 0.028785396676807865\n",
      " shared 2411\n",
      " shared/to  0.5642405803884858\n",
      "BUTTS ROBERT H\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "OLSON CINDY K\n",
      " to 1184\n",
      " from 52\n",
      " to_poi 15\n",
      " to poi/from 0.28846153846153844\n",
      " from_poi 20\n",
      " from poi/to 0.016891891891891893\n",
      " shared 856\n",
      " shared/to  0.722972972972973\n",
      "MCDONALD REBECCA\n",
      " to 894\n",
      " from 13\n",
      " to_poi 1\n",
      " to poi/from 0.07692307692307693\n",
      " from_poi 54\n",
      " from poi/to 0.06040268456375839\n",
      " shared 720\n",
      " shared/to  0.8053691275167785\n",
      "CUMBERLAND MICHAEL S\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "GAHN ROBERT S\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "BADUM JAMES P\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "HERMANN ROBERT J\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "FALLON JAMES B\n",
      " to 1755\n",
      " from 75\n",
      " to_poi 37\n",
      " to poi/from 0.49333333333333335\n",
      " from_poi 42\n",
      " from poi/to 0.023931623931623933\n",
      " shared 1604\n",
      " shared/to  0.913960113960114\n",
      "GATHMANN WILLIAM D\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "HORTON STANLEY C\n",
      " to 2350\n",
      " from 1073\n",
      " to_poi 15\n",
      " to poi/from 0.013979496738117428\n",
      " from_poi 44\n",
      " from poi/to 0.01872340425531915\n",
      " shared 1074\n",
      " shared/to  0.4570212765957447\n",
      "BOWEN JR RAYMOND M\n",
      " to 1858\n",
      " from 27\n",
      " to_poi 15\n",
      " to poi/from 0.5555555555555556\n",
      " from_poi 140\n",
      " from poi/to 0.07534983853606028\n",
      " shared 1593\n",
      " shared/to  0.8573735199138859\n",
      "GILLIS JOHN\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "FITZGERALD JAY L\n",
      " to 936\n",
      " from 16\n",
      " to_poi 8\n",
      " to poi/from 0.5\n",
      " from_poi 1\n",
      " from poi/to 0.0010683760683760685\n",
      " shared 723\n",
      " shared/to  0.7724358974358975\n",
      "MORAN MICHAEL P\n",
      " to 672\n",
      " from 19\n",
      " to_poi 0\n",
      " to poi/from 0.0\n",
      " from_poi 0\n",
      " from poi/to 0.0\n",
      " shared 127\n",
      " shared/to  0.18898809523809523\n",
      "REDMOND BRIAN L\n",
      " to 1671\n",
      " from 221\n",
      " to_poi 49\n",
      " to poi/from 0.22171945701357465\n",
      " from_poi 204\n",
      " from poi/to 0.12208258527827648\n",
      " shared 1063\n",
      " shared/to  0.6361460203470976\n",
      "BAZELIDES PHILIP J\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "BELDEN TIMOTHY N\n",
      " to 7991\n",
      " from 484\n",
      " to_poi 108\n",
      " to poi/from 0.2231404958677686\n",
      " from_poi 228\n",
      " from poi/to 0.028532098610937303\n",
      " shared 5521\n",
      " shared/to  0.6909022650481792\n",
      "DIMICHELE RICHARD G\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "DURAN WILLIAM D\n",
      " to 904\n",
      " from 12\n",
      " to_poi 3\n",
      " to poi/from 0.25\n",
      " from_poi 106\n",
      " from poi/to 0.1172566371681416\n",
      " shared 599\n",
      " shared/to  0.6626106194690266\n",
      "THORN TERENCE H\n",
      " to 266\n",
      " from 41\n",
      " to_poi 0\n",
      " to poi/from 0.0\n",
      " from_poi 0\n",
      " from poi/to 0.0\n",
      " shared 73\n",
      " shared/to  0.2744360902255639\n",
      "FASTOW ANDREW S\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "FOY JOE\n",
      " to 57\n",
      " from 13\n",
      " to_poi 0\n",
      " to poi/from 0.0\n",
      " from_poi 0\n",
      " from poi/to 0.0\n",
      " shared 2\n",
      " shared/to  0.03508771929824561\n",
      "CALGER CHRISTOPHER F\n",
      " to 2598\n",
      " from 144\n",
      " to_poi 25\n",
      " to poi/from 0.1736111111111111\n",
      " from_poi 199\n",
      " from poi/to 0.07659738260200154\n",
      " shared 2188\n",
      " shared/to  0.8421862971516552\n",
      "RICE KENNETH D\n",
      " to 905\n",
      " from 18\n",
      " to_poi 4\n",
      " to poi/from 0.2222222222222222\n",
      " from_poi 42\n",
      " from poi/to 0.04640883977900553\n",
      " shared 864\n",
      " shared/to  0.9546961325966851\n",
      "KAMINSKI WINCENTY J\n",
      " to 4607\n",
      " from 14368\n",
      " to_poi 171\n",
      " to poi/from 0.011901447661469933\n",
      " from_poi 41\n",
      " from poi/to 0.008899500759713479\n",
      " shared 583\n",
      " shared/to  0.1265465595832429\n",
      "COX DAVID\n",
      " to 102\n",
      " from 33\n",
      " to_poi 4\n",
      " to poi/from 0.12121212121212122\n",
      " from_poi 0\n",
      " from poi/to 0.0\n",
      " shared 71\n",
      " shared/to  0.696078431372549\n",
      "OVERDYKE JR JERE C\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "PEREIRA PAULO V. FERRAZ\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "STABLER FRANK\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "SKILLING JEFFREY K\n",
      " to 3627\n",
      " from 108\n",
      " to_poi 30\n",
      " to poi/from 0.2777777777777778\n",
      " from_poi 88\n",
      " from poi/to 0.0242624758753791\n",
      " shared 2042\n",
      " shared/to  0.5629997242900469\n",
      "BLAKE JR. NORMAN P\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "SHERRICK JEFFREY B\n",
      " to 613\n",
      " from 25\n",
      " to_poi 18\n",
      " to poi/from 0.72\n",
      " from_poi 39\n",
      " from poi/to 0.0636215334420881\n",
      " shared 583\n",
      " shared/to  0.9510603588907015\n",
      "PRENTICE JAMES\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "GRAY RODNEY\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "UMANOFF ADAM S\n",
      " to 111\n",
      " from 18\n",
      " to_poi 0\n",
      " to poi/from 0.0\n",
      " from_poi 12\n",
      " from poi/to 0.10810810810810811\n",
      " shared 41\n",
      " shared/to  0.36936936936936937\n",
      "KEAN STEVEN J\n",
      " to 12754\n",
      " from 6759\n",
      " to_poi 387\n",
      " to poi/from 0.05725699067909454\n",
      " from_poi 140\n",
      " from poi/to 0.010976948408342482\n",
      " shared 3639\n",
      " shared/to  0.2853222518425592\n",
      "FOWLER PEGGY\n",
      " to 517\n",
      " from 36\n",
      " to_poi 0\n",
      " to poi/from 0.0\n",
      " from_poi 0\n",
      " from poi/to 0.0\n",
      " shared 10\n",
      " shared/to  0.019342359767891684\n",
      "WASAFF GEORGE\n",
      " to 400\n",
      " from 30\n",
      " to_poi 7\n",
      " to poi/from 0.23333333333333334\n",
      " from_poi 22\n",
      " from poi/to 0.055\n",
      " shared 337\n",
      " shared/to  0.8425\n",
      "WHITE JR THOMAS E\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "CHRISTODOULOU DIOMEDES\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "ALLEN PHILLIP K\n",
      " to 2902\n",
      " from 2195\n",
      " to_poi 65\n",
      " to poi/from 0.029612756264236904\n",
      " from_poi 47\n",
      " from poi/to 0.016195727084769126\n",
      " shared 1407\n",
      " shared/to  0.4848380427291523\n",
      "SHARP VICTORIA T\n",
      " to 3136\n",
      " from 136\n",
      " to_poi 6\n",
      " to poi/from 0.04411764705882353\n",
      " from_poi 24\n",
      " from poi/to 0.007653061224489796\n",
      " shared 2477\n",
      " shared/to  0.7898596938775511\n",
      "JAEDICKE ROBERT\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "WINOKUR JR. HERBERT S\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "BROWN MICHAEL\n",
      " to 1486\n",
      " from 41\n",
      " to_poi 1\n",
      " to poi/from 0.024390243902439025\n",
      " from_poi 13\n",
      " from poi/to 0.008748317631224764\n",
      " shared 761\n",
      " shared/to  0.5121130551816958\n",
      "MCCLELLAN GEORGE\n",
      " to 1744\n",
      " from 49\n",
      " to_poi 0\n",
      " to poi/from 0.0\n",
      " from_poi 52\n",
      " from poi/to 0.02981651376146789\n",
      " shared 1469\n",
      " shared/to  0.8423165137614679\n",
      "HUGHES JAMES A\n",
      " to 719\n",
      " from 34\n",
      " to_poi 5\n",
      " to poi/from 0.14705882352941177\n",
      " from_poi 35\n",
      " from poi/to 0.048678720445062586\n",
      " shared 589\n",
      " shared/to  0.8191933240611962\n",
      "REYNOLDS LAWRENCE\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "PICKERING MARK R\n",
      " to 898\n",
      " from 67\n",
      " to_poi 0\n",
      " to poi/from 0.0\n",
      " from_poi 7\n",
      " from poi/to 0.0077951002227171495\n",
      " shared 728\n",
      " shared/to  0.8106904231625836\n",
      "BHATNAGAR SANJAY\n",
      " to 523\n",
      " from 29\n",
      " to_poi 1\n",
      " to poi/from 0.034482758620689655\n",
      " from_poi 0\n",
      " from poi/to 0.0\n",
      " shared 463\n",
      " shared/to  0.8852772466539197\n",
      "CARTER REBECCA C\n",
      " to 312\n",
      " from 15\n",
      " to_poi 7\n",
      " to poi/from 0.4666666666666667\n",
      " from_poi 29\n",
      " from poi/to 0.09294871794871795\n",
      " shared 196\n",
      " shared/to  0.6282051282051282\n",
      "BUCHANAN HAROLD G\n",
      " to 1088\n",
      " from 125\n",
      " to_poi 0\n",
      " to poi/from 0.0\n",
      " from_poi 0\n",
      " from poi/to 0.0\n",
      " shared 23\n",
      " shared/to  0.021139705882352942\n",
      "YEAP SOON\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "MURRAY JULIA H\n",
      " to 2192\n",
      " from 45\n",
      " to_poi 2\n",
      " to poi/from 0.044444444444444446\n",
      " from_poi 11\n",
      " from poi/to 0.005018248175182482\n",
      " shared 395\n",
      " shared/to  0.1802007299270073\n",
      "GARLAND C KEVIN\n",
      " to 209\n",
      " from 44\n",
      " to_poi 27\n",
      " to poi/from 0.6136363636363636\n",
      " from_poi 10\n",
      " from poi/to 0.04784688995215311\n",
      " shared 178\n",
      " shared/to  0.8516746411483254\n",
      "DODSON KEITH\n",
      " to 176\n",
      " from 14\n",
      " to_poi 3\n",
      " to poi/from 0.21428571428571427\n",
      " from_poi 10\n",
      " from poi/to 0.056818181818181816\n",
      " shared 114\n",
      " shared/to  0.6477272727272727\n",
      "YEAGER F SCOTT\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "HIRKO JOSEPH\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "DIETRICH JANET R\n",
      " to 2572\n",
      " from 63\n",
      " to_poi 14\n",
      " to poi/from 0.2222222222222222\n",
      " from_poi 305\n",
      " from poi/to 0.11858475894245724\n",
      " shared 1902\n",
      " shared/to  0.73950233281493\n",
      "DERRICK JR. JAMES V\n",
      " to 2181\n",
      " from 909\n",
      " to_poi 20\n",
      " to poi/from 0.022002200220022004\n",
      " from_poi 64\n",
      " from poi/to 0.029344337459880788\n",
      " shared 1401\n",
      " shared/to  0.6423658872077029\n",
      "FREVERT MARK A\n",
      " to 3275\n",
      " from 21\n",
      " to_poi 6\n",
      " to poi/from 0.2857142857142857\n",
      " from_poi 242\n",
      " from poi/to 0.07389312977099237\n",
      " shared 2979\n",
      " shared/to  0.909618320610687\n",
      "PAI LOU L\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "HAYSLETT RODERICK J\n",
      " to 2649\n",
      " from 1061\n",
      " to_poi 38\n",
      " to poi/from 0.03581526861451461\n",
      " from_poi 35\n",
      " from poi/to 0.01321253303133258\n",
      " shared 571\n",
      " shared/to  0.21555303888259722\n",
      "BAY FRANKLIN R\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "MCCARTY DANNY J\n",
      " to 1433\n",
      " from 215\n",
      " to_poi 2\n",
      " to poi/from 0.009302325581395349\n",
      " from_poi 25\n",
      " from poi/to 0.017445917655268667\n",
      " shared 508\n",
      " shared/to  0.35450104675505933\n",
      "FUGH JOHN L\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "SCRIMSHAW MATTHEW\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "KOENIG MARK E\n",
      " to 2374\n",
      " from 61\n",
      " to_poi 15\n",
      " to poi/from 0.2459016393442623\n",
      " from_poi 53\n",
      " from poi/to 0.02232518955349621\n",
      " shared 2271\n",
      " shared/to  0.9566133108677338\n",
      "SAVAGE FRANK\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "IZZO LAWRENCE L\n",
      " to 496\n",
      " from 19\n",
      " to_poi 5\n",
      " to poi/from 0.2631578947368421\n",
      " from_poi 28\n",
      " from poi/to 0.056451612903225805\n",
      " shared 437\n",
      " shared/to  0.8810483870967742\n",
      "TILNEY ELIZABETH A\n",
      " to 460\n",
      " from 19\n",
      " to_poi 11\n",
      " to poi/from 0.5789473684210527\n",
      " from_poi 10\n",
      " from poi/to 0.021739130434782608\n",
      " shared 379\n",
      " shared/to  0.8239130434782609\n",
      "MARTIN AMANDA K\n",
      " to 1522\n",
      " from 230\n",
      " to_poi 0\n",
      " to poi/from 0.0\n",
      " from_poi 8\n",
      " from poi/to 0.005256241787122208\n",
      " shared 477\n",
      " shared/to  0.31340341655716164\n",
      "BUY RICHARD B\n",
      " to 3523\n",
      " from 1053\n",
      " to_poi 71\n",
      " to poi/from 0.06742640075973409\n",
      " from_poi 156\n",
      " from poi/to 0.04428044280442804\n",
      " shared 2333\n",
      " shared/to  0.6622196991200682\n",
      "GRAMM WENDY L\n",
      " to NaN\n",
      " from NaN\n",
      " to_poi NaN\n",
      " to poi/from NaN\n",
      " from_poi NaN\n",
      " from poi/to NaN\n",
      " shared NaN\n",
      " shared/to  NaN\n",
      "CAUSEY RICHARD A\n",
      " to 1892\n",
      " from 49\n",
      " to_poi 12\n",
      " to poi/from 0.24489795918367346\n",
      " from_poi 58\n",
      " from poi/to 0.0306553911205074\n",
      " shared 1585\n",
      " shared/to  0.837737843551797\n",
      "TAYLOR MITCHELL S\n",
      " to 533\n",
      " from 29\n",
      " to_poi 0\n",
      " to poi/from 0.0\n",
      " from_poi 0\n",
      " from poi/to 0.0\n",
      " shared 300\n",
      " shared/to  0.5628517823639775\n",
      "DONAHUE JR JEFFREY M\n",
      " to 865\n",
      " from 22\n",
      " to_poi 11\n",
      " to poi/from 0.5\n",
      " from_poi 188\n",
      " from poi/to 0.21734104046242775\n",
      " shared 772\n",
      " shared/to  0.892485549132948\n",
      "GLISAN JR BEN F\n",
      " to 873\n",
      " from 16\n",
      " to_poi 6\n",
      " to poi/from 0.375\n",
      " from_poi 52\n",
      " from poi/to 0.05956471935853379\n",
      " shared 874\n",
      " shared/to  1.0011454753722795\n"
     ]
    }
   ],
   "source": [
    "for k in data_dict.keys():\n",
    "  print(k)\n",
    "  print(\" to\", data_dict[k]['to_messages'])\n",
    "  print(\" from\", data_dict[k]['from_messages'])\n",
    "  print(\" to_poi\", data_dict[k]['from_this_person_to_poi'])\n",
    "  print(\" to poi/from\",data_dict[k]['to_poi_from_messages_ratio'])\n",
    "  print(\" from_poi\", data_dict[k]['from_poi_to_this_person'])\n",
    "  print(\" from poi/to\",data_dict[k]['from_poi_to_messages_ratio'])\n",
    "  print(\" shared\",data_dict[k]['shared_receipt_with_poi'])\n",
    "  print(\" shared/to \",data_dict[k]['shared_receipt_to_messages_ratio'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a58d98",
   "metadata": {},
   "source": [
    "Looking through the values for these new ratios shown above, they do generally make sense, falling between 0 and 1. With the addition of these new ratio features, the number of features in our dataset is now 23."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "20cef062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "features_list = ['poi',\n",
    "                 'salary',\n",
    "                 'bonus',\n",
    "                 'long_term_incentive',\n",
    "                 'expenses',\n",
    "                 'director_fees',\n",
    "                 'other',\n",
    "                 'loan_advances',\n",
    "                 'deferred_income',\n",
    "                 'deferral_payments',\n",
    "                 'total_payments',\n",
    "                 'restricted_stock_deferred',\n",
    "                 'exercised_stock_options',\n",
    "                 'restricted_stock',\n",
    "                 'total_stock_value',\n",
    "                 'from_messages',\n",
    "                 'to_messages',\n",
    "                 'from_poi_to_this_person',\n",
    "                 'from_this_person_to_poi',\n",
    "                 'shared_receipt_with_poi',\n",
    "                 'from_poi_to_messages_ratio',\n",
    "                 'to_poi_from_messages_ratio',\n",
    "                 'shared_receipt_to_messages_ratio']\n",
    "\n",
    "print (len(features_list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb366c5",
   "metadata": {},
   "source": [
    "## Initial Algorithm Development "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a89bbea",
   "metadata": {},
   "source": [
    "Initially, I decided to evaluate the differences between the  DecisionTreeClassifier, KNeighborsClassifier (K Nearest Neighbors), and GaussianNB (Gaussian Naive Bayes) algorithms. In reviewing tester.py and noting that its test_classification() method applied K-fold cross-validation prior to iterative fitting and prediction, it made the most sense to me to attempt to follow that function's approach so that my algorithm of choice would follow the same grading metrics: accuracy, precision, recall, F1, and F2, each as ratios calculated from sums for comparisons of predictions and labels across 1000 testing-training splits of the dataset. This would essentially produce a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a03ff07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_format import featureFormat, targetFeatureSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6ab25cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying several classifiers with default settings for comparison...\n",
      "\n",
      "KNeighborsClassifier()\n",
      "  Predictions: 15000\n",
      "  Accuracy: 0.87513\n",
      "  Precision: 0.61609  Recall: 0.16850\n",
      "  F1: 0.26463  F2: 0.19715 \n",
      "\n",
      "DecisionTreeClassifier()\n",
      "  Predictions: 15000\n",
      "  Accuracy: 0.80320\n",
      "  Precision: 0.26224  Recall: 0.26250\n",
      "  F1: 0.26237  F2: 0.26245 \n",
      "\n",
      "GaussianNB()\n",
      "  Predictions: 15000\n",
      "  Accuracy: 0.76353\n",
      "  Precision: 0.24564  Recall: 0.37350\n",
      "  F1: 0.29637  F2: 0.33828 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors         import KNeighborsClassifier\n",
    "from sklearn.tree              import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes       import GaussianNB\n",
    "from sklearn.ensemble          import AdaBoostClassifier\n",
    "from sklearn.model_selection   import StratifiedShuffleSplit\n",
    "\n",
    "# Function definition for classifier testing, validation, evaluation\n",
    "def classifier_test(clf, dataset, feature_list, folds = 1000):\n",
    "  data = featureFormat(dataset, feature_list, sort_keys = True)\n",
    "  labels, features = targetFeatureSplit(data)\n",
    "  cv = StratifiedShuffleSplit(n_splits=folds, random_state = 42)\n",
    "  true_neg  = 0\n",
    "  false_neg = 0\n",
    "  true_pos  = 0\n",
    "  false_pos = 0\n",
    "  for train_idx, test_idx in cv.split(features, labels):\n",
    "    features_train = []\n",
    "    labels_train   = []\n",
    "    features_test  = []\n",
    "    labels_test    = []\n",
    "    for ii in train_idx:\n",
    "      features_train.append(features[ii])\n",
    "      labels_train.append(labels[ii])\n",
    "    for jj in test_idx:\n",
    "      features_test.append(features[jj])\n",
    "      labels_test.append(labels[jj])\n",
    "\n",
    "    # fit the classifier using training set, and test on test set\n",
    "    clf.fit(features_train, labels_train)\n",
    "    predictions = clf.predict(features_test)\n",
    "    for prediction, truth in zip(predictions, labels_test):\n",
    "      if prediction == 0 and truth == 0:\n",
    "        true_neg += 1\n",
    "      elif prediction == 0 and truth == 1:\n",
    "        false_neg += 1\n",
    "      elif prediction == 1 and truth == 0:\n",
    "        false_pos += 1\n",
    "      elif prediction == 1 and truth == 1:\n",
    "        true_pos += 1\n",
    "      else:\n",
    "        print(\"Warning: Found a predicted label not == 0 or 1.\")\n",
    "        print(\"All predictions should take value 0 or 1.\")\n",
    "        print(\"Evaluating performance for processed predictions:\")\n",
    "        break\n",
    "  try:\n",
    "    total_pred = true_neg + false_neg + false_pos + true_pos\n",
    "    accuracy = 1.0 * (true_pos + true_neg) / total_pred\n",
    "    precision = 1.0 * true_pos / (true_pos + false_pos)\n",
    "    recall = 1.0 * true_pos / (true_pos + false_neg)\n",
    "    f1 = 2.0 * true_pos / (2 * true_pos + false_pos + false_neg)\n",
    "    f2 = (1 + 2.0 * 2.0) * precision * recall / (4 * precision + recall)\n",
    "    print(clf)\n",
    "    print(\"  Predictions: %d\" % total_pred)\n",
    "    print(\"  Accuracy: %.5f\\n  Precision: %.5f  Recall: %.5f\" % \\\n",
    "          (accuracy, precision, recall))\n",
    "    print(\"  F1: %.5f  F2: %.5f\" % (f1, f2), \"\\n\")\n",
    "  except:\n",
    "    print(\"Performance calculations failed.\")\n",
    "    print(\"Precision or recall may be undefined (no true positives).\")\n",
    "\n",
    "# Iteration over a list of classifiers\n",
    "classifiers = [KNeighborsClassifier(),\n",
    "               DecisionTreeClassifier(),\n",
    "               GaussianNB()]\n",
    "\n",
    "print(\"Trying several classifiers with default settings for comparison...\\n\")\n",
    "for classifier in classifiers:\n",
    "  classifier_test(classifier, data_dict, features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b4d4a8",
   "metadata": {},
   "source": [
    "With the initial, default settings used, the above results were produced. KNeighBorsClassifier ranked highest in accuracy at 0.87513 and precision at 0.61909, but lowest in recall at 0.16850. DecisionTreeClassifier was slightly better at performing than GaussianNB in accuracy at 0.80367 and precision at 0.25732, but was worse in recall at 0.25050. GaussianNB had the best recall at 0.37350, but the least accuracy (at 0.76353) or precision (at 0.24564).\n",
    "\n",
    "With those results in mind, I decided to pursue more extensive testing and parameter tuning for the DecisionTreeClassifier and KNeighborsClassifier. After addition tuning for feature selection and parameter settings could not produce sufficient recall, the decision was made to discard the KNeighborsClassifier. Despite its relatively high recall score, due to the relative inflexibility of GaussianNB to tune parameters, this algorithm was discarded fairly early in the process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcab2a80",
   "metadata": {},
   "source": [
    "## Investigating Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375fe41b",
   "metadata": {},
   "source": [
    "After testing a few different classifiers, I was interested in taking a deeper look at feature importance. Several different methods were used to examine feature importance before settling on 'mutual information' values derived from sklearn.feature_selection.mutual_info_classif(). I found that using this produced meaningful increases in algorithm performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c53b96b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature importance by mutual_info_classif:\n",
      " ('mutual info' with regard to 'poi' target)\n",
      "  1 - 'bonus' \n",
      "        0.08911\n",
      "  2 - 'expenses' \n",
      "        0.08035\n",
      "  3 - 'other' \n",
      "        0.06814\n",
      "  4 - 'to_poi_from_messages_ratio' \n",
      "        0.05753\n",
      "  5 - 'shared_receipt_with_poi' \n",
      "        0.05629\n",
      "  6 - 'restricted_stock' \n",
      "        0.03974\n",
      "  7 - 'total_stock_value' \n",
      "        0.03778\n",
      "  8 - 'from_poi_to_messages_ratio' \n",
      "        0.03150\n",
      "  9 - 'exercised_stock_options' \n",
      "        0.02915\n",
      "  10 - 'shared_receipt_to_messages_ratio' \n",
      "        0.02590\n",
      "  11 - 'salary' \n",
      "        0.02473\n",
      "  12 - 'from_this_person_to_poi' \n",
      "        0.02328\n",
      "  13 - 'loan_advances' \n",
      "        0.01632\n",
      "  14 - 'total_payments' \n",
      "        0.01453\n",
      "  15 - 'to_messages' \n",
      "        0.00780\n",
      "  16 - 'deferred_income' \n",
      "        0.00739\n",
      "  17 - 'restricted_stock_deferred' \n",
      "        0.00510\n",
      "  18 - 'from_messages' \n",
      "        0.00106\n",
      "  19 - 'long_term_incentive' \n",
      "        0.00064\n",
      "  20 - 'from_poi_to_this_person' \n",
      "        0.00000\n",
      "  21 - 'director_fees' \n",
      "        0.00000\n",
      "  22 - 'deferral_payments' \n",
      "        0.00000\n"
     ]
    }
   ],
   "source": [
    "# for feature and label extraction\n",
    "features_list = ['poi',\n",
    "                 'salary',\n",
    "                 'bonus',\n",
    "                 'long_term_incentive',\n",
    "                 'expenses',\n",
    "                 'director_fees',\n",
    "                 'other',\n",
    "                 'loan_advances',\n",
    "                 'deferred_income',\n",
    "                 'deferral_payments',\n",
    "                 'total_payments',\n",
    "                 'restricted_stock_deferred',\n",
    "                 'exercised_stock_options',\n",
    "                 'restricted_stock',\n",
    "                 'total_stock_value',\n",
    "                 'from_messages',\n",
    "                 'to_messages',\n",
    "                 'from_poi_to_this_person',\n",
    "                 'from_this_person_to_poi',\n",
    "                 'shared_receipt_with_poi',\n",
    "                 'from_poi_to_messages_ratio',\n",
    "                 'to_poi_from_messages_ratio',\n",
    "                 'shared_receipt_to_messages_ratio']\n",
    "\n",
    "# Extracting features and labels from dataset for local testing\n",
    "data = featureFormat(data_dict, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "print(\"\\nFeature importance by mutual_info_classif:\")\n",
    "print(\" ('mutual info' with regard to 'poi' target)\")\n",
    "# sorting feature names by magnitude of mutual information with 'poi'\n",
    "mutual_info = sorted(zip(list(mutual_info_classif(features, labels)),\n",
    "                         features_list[1:]), reverse = True)\n",
    "for i in range(len(mutual_info)):\n",
    "  print(\" \", i+1, \"- '%s'\" % mutual_info[i][1],\n",
    "        \"\\n        %.5f\"   % mutual_info[i][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045977e1",
   "metadata": {},
   "source": [
    "The top five features by importance shown by the mutual_info_classif were selected as the features for the final algorithm. Those features are, in order of importance:\n",
    "- expenses\n",
    "- bonus\n",
    "- other\n",
    "- shared_receipt_with_poi\n",
    "- to_poi_from_messages_ratio\n",
    "\n",
    "I found it interesting to note that one of the newly created features, to_poi_from_messages_ratio made it into the final feature selection choice. \n",
    "\n",
    "It is also important to note that no feature scaling was performed here, as this is not required for successful performance of the DecisionTreeClassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511c2de2",
   "metadata": {},
   "source": [
    "## Algorithm Tuning Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0aef11",
   "metadata": {},
   "source": [
    "Tuning parameters for the purposes of a classification algorithm is the iterative process of changing settings for the behaviour of the classifiers with the intent to increase performance. This increased performance can be seen in either minimizing runtime or maximizing evaluation metrics such as accuracy, precision, recall, and/or composites like f1, f2. Poor parameter tuning could result in inefficiently long runtime, and/or poorly optimized results. This is why parameter tuning is of such importance.\n",
    "\n",
    "Algorithm tuning is generally an iterative process, and that was the process I followed here. I first sought to maximize precision and accuracy by use of GridSearchCV with SelectKBest and DecisionTreeClassifier, optimizing parameters for maximized F1.\n",
    "\n",
    "After several attempts, I found the best performance by using mutual information as the feature selection metric along with information gain as the splitting criterion. I sought to minimize runtime by keeping the chosen parameters fixed. Then, I sought to optimize for 'k' in SelectKBes and 'min_samples_split' in DecisionTreeClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "069a6e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif, SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d8c87082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying GridSearchCV with\n",
      "Pipeline(steps=[('skb',\n",
      "                 SelectKBest(score_func=<function mutual_info_classif at 0x0000017BC8386CA0>)),\n",
      "                ('clf', DecisionTreeClassifier(criterion='entropy'))])\n",
      "over parameters:\n",
      "{'clf__min_samples_split': (3, 4, 5, 6, 7, 8, 9),\n",
      " 'skb__k': (3, 4, 5, 6, 7, 8, 9)}\n",
      "\n",
      "Resulting 'best' parameters for maximizing 'f1':\n",
      "{'clf__min_samples_split': 4, 'skb__k': 5}\n",
      "\n",
      "Features used:\n",
      "  1 - 'expenses' \n",
      "        0.08268\n",
      "  2 - 'bonus' \n",
      "        0.07398\n",
      "  3 - 'other' \n",
      "        0.06814\n",
      "  4 - 'to_poi_from_messages_ratio' \n",
      "        0.05794\n",
      "  5 - 'shared_receipt_with_poi' \n",
      "        0.04604\n",
      "\n",
      "DecisionTreeClassifier(criterion='entropy', min_samples_split=4)\n",
      "  Predictions: 13000\n",
      "  Accuracy: 0.84262\n",
      "  Precision: 0.48793  Recall: 0.46500\n",
      "  F1: 0.47619  F2: 0.46941 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline        import Pipeline\n",
    "\n",
    "# Using mutual information as feature selection metric\n",
    "selector = SelectKBest(mutual_info_classif)\n",
    "# Using information (entropy) gain as splitting criterion\n",
    "classifier = DecisionTreeClassifier(criterion = 'entropy')\n",
    "\n",
    "tune_pipe = Pipeline(steps=[('skb', selector),\n",
    "                            ('clf', classifier)])\n",
    "\n",
    "# Optimizing number of features and minimum number of samples for splitting\n",
    "grid_params = {'skb__k' : (3, 4, 5, 6, 7, 8, 9),\n",
    "                'clf__min_samples_split' : (3, 4, 5, 6, 7, 8, 9)}\n",
    "\n",
    "print(\"Trying GridSearchCV with\")\n",
    "pp(tune_pipe)\n",
    "print(\"over parameters:\")\n",
    "pp(grid_params)\n",
    "\n",
    "# Optimizing for maximized F1 in order to maximize precison and recall\n",
    "grid = GridSearchCV(tune_pipe, grid_params, scoring = 'f1', cv = 10,\n",
    "                    n_jobs = -1)\n",
    "grid.fit(features, labels)\n",
    "\n",
    "print(\"\\nResulting 'best' parameters for maximizing 'f1':\")\n",
    "pp(grid.best_params_)\n",
    "\n",
    "# sorting features by paired information gain scores\n",
    "grid_ftrs = sorted(zip(list(grid.best_estimator_.named_steps['skb'].scores_),\n",
    "                             features_list[1:]), reverse = True)\n",
    "# creating list to pass to k-fold testing method\n",
    "best_features = ['poi']\n",
    "print(\"\\nFeatures used:\")\n",
    "for i in range(grid.best_params_['skb__k']):\n",
    "  best_features.append(grid_ftrs[i][1])\n",
    "  print(\" \", i+1, \"- '%s'\" % grid_ftrs[i][1],\n",
    "        \"\\n        %.5f\"   % grid_ftrs[i][0])\n",
    "print('')\n",
    "\n",
    "# Testing tuned parameters with 1000-fold cross validation\n",
    "classifier_test(grid.best_estimator_.named_steps['clf'],data_dict,\n",
    "                best_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b6113f",
   "metadata": {},
   "source": [
    "As shown in the above code, in order to observe performance results, the best-parametered classifier and best-performing features from GridSearchCV were passed to the previous 1000-fold cross validation testing function.\n",
    "\n",
    "Multiple executions of this code resulted in slightly varying 'k', 'min_samples_split', and the exact features selected. This is likely not a cause for concern due to the inherent variation possible for mutual information scores and the variation possible fin the  DecisionTreeClassifier due to its node-splitting method.\n",
    "\n",
    "Performance seems to be maximized with 'min_samples_split' set to 5, 'k' set to 5, with the features previously discussed. Given that information, I elected to manually test those values for their performance results from the testing function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aa14e9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying DecisionTreeClassifier with parameter settings and feature\n",
      "  selection based on 'best' of varying results from optimization...\n",
      "  (features *reliably* top-ranked by 'mutual information' with 'poi')\n",
      "Features used:\n",
      "['expenses',\n",
      " 'bonus',\n",
      " 'other',\n",
      " 'to_poi_from_messages_ratio',\n",
      " 'shared_receipt_with_poi']\n",
      "DecisionTreeClassifier(criterion='entropy', min_samples_split=5)\n",
      "  Predictions: 13000\n",
      "  Accuracy: 0.84369\n",
      "  Precision: 0.49153  Recall: 0.46400\n",
      "  F1: 0.47737  F2: 0.46926 \n",
      "\n",
      "Testing final classifier via tester.py...\n",
      "DecisionTreeClassifier(criterion='entropy', min_samples_split=5)\n",
      "\tAccuracy: 0.84515\tPrecision: 0.49651\tRecall: 0.46200\tF1: 0.47863\tF2: 0.46851\n",
      "\tTotal predictions: 13000\tTrue positives:  924\tFalse positives:  937\tFalse negatives: 1076\tTrue negatives: 10063\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# features (apart from 'poi') that were most frequently top-ranked in mutual information\n",
    "manual_features = ['poi',\n",
    "                   'expenses',\n",
    "                   'bonus',\n",
    "                   'other',\n",
    "                   'to_poi_from_messages_ratio',\n",
    "                   'shared_receipt_with_poi']\n",
    "\n",
    "# parameter settings most frequently resultingin highest precision and recall\n",
    "clf = DecisionTreeClassifier(criterion = 'entropy',\n",
    "                             min_samples_split = 5)\n",
    "\n",
    "print(\"Trying DecisionTreeClassifier with parameter settings and feature\")\n",
    "print(\"  selection based on 'best' of varying results from optimization...\")\n",
    "print(\"  (features *reliably* top-ranked by 'mutual information' with 'poi')\")\n",
    "print(\"Features used:\")\n",
    "pp(manual_features[1:])\n",
    "classifier_test(clf, data_dict, manual_features)\n",
    "\n",
    "# Dumping classifier, dataset, features list, and running tester.py for final test\n",
    "import tester\n",
    "print(\"Testing final classifier via tester.py...\")\n",
    "tester.dump_classifier_and_data(clf, data_dict, manual_features)\n",
    "tester.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6993e7",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4faa8935",
   "metadata": {},
   "source": [
    "As shown in the above code samples, the algorithm I ultimately chose was a DecisionTreeClassifier. This algorithm was set to use entropy (as information gain) for the splitting criterion as well as a minimum of 5 samples for splitting of internal nodes. Based on investigation of feature importance via mutual information, the algorithm was applied to a subset of features, namely 'expenses', 'bonus', 'other', 'to_poi_from_messages_ratio', and 'shared_receipt_with_poi'.\n",
    "\n",
    "In machine learning, validation is a method of testing a model’s performance by splitting the data into training and testing data. The model is trained with the training dataset and it is tested with the testing dataset, thereby maintaining independence between the two datasets. The performance of the algorithm is therefore able to be validated  when the model is applied on the testing dataset. Overfitting may occur without proper validation, meaning accuracy and other metrics may be higher than those possible for any independent data secondary to recognition of feature values from those used in training the classifier.\n",
    "\n",
    "This project employed k-fold cross validation in a manner consistent with that applied by tester.py. The dataset was split by StratifiedShuffleSplit with a default of 1000 for its n_splits parameter. Subsequently, performance metrics were calculated according to totals for all predictions, true positives, false positives, true negatives, and false negatives from the classifier.\n",
    "\n",
    "Accuracy of the final classifier was generally around0.84, with precision of about 0.49, and recall of about 0.46. In human-speak, this means that the algorithm devised here is able to correctly predict a record's status as a POI around 84% of the time. From the recall score of 0.46, we can deduce that correct positive predictions were about 46% of all potentially positive predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1c63de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
